# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Git Management Policy

### Automatic Git Operations
- **Commit Frequency**: å¤‰æ›´ã”ã¨ã«å¿…ãšã‚³ãƒŸãƒƒãƒˆã™ã‚‹ï¼ˆå¿˜ã‚Œãªã„ã‚ˆã†ã«ï¼‰
- **Commit Messages**: ç›®çš„ã‚’æ˜ç¢ºã«è¨˜è¿°ã—ãŸæ„å‘³ã®ã‚ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
- **Staging**: é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–
- **Format**: æ—¥æœ¬èªãƒ»è‹±èªã§ã®å¾“æ¥å‹ã‚³ãƒŸãƒƒãƒˆå½¢å¼ã«å¾“ã†

### Branch Strategy (Git Flow)

**Main Branches:**
- `main`: æœ¬ç•ªç’°å¢ƒç”¨ã®å®‰å®šç‰ˆã‚³ãƒ¼ãƒ‰
- `develop`: é–‹ç™ºçµ±åˆãƒ–ãƒ©ãƒ³ãƒ

**Supporting Branches:**
- `feature/[feature-name]`: æ–°æ©Ÿèƒ½é–‹ç™ºç”¨
- `hotfix/[issue-name]`: ç·Šæ€¥ä¿®æ­£ç”¨  
- `release/[version]`: ãƒªãƒªãƒ¼ã‚¹æº–å‚™ç”¨

**Workflow:**
```bash
# æ–°æ©Ÿèƒ½é–‹ç™º
git checkout develop
git checkout -b feature/new-feature
# ... é–‹ç™ºãƒ»ã‚³ãƒŸãƒƒãƒˆ ...
git checkout develop
git merge feature/new-feature
git branch -d feature/new-feature

# ãƒªãƒªãƒ¼ã‚¹æº–å‚™
git checkout develop
git checkout -b release/v1.0.0
# ... ãƒã‚°ä¿®æ­£ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–° ...
git checkout main
git merge release/v1.0.0
git tag v1.0.0
git checkout develop
git merge release/v1.0.0
```

### Commit Message Convention

**Format:**
```
<type>(<scope>): <subject>

<body>

ğŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude <noreply@anthropic.com>
```

**Types:**
- `feat`: æ–°æ©Ÿèƒ½
- `fix`: ãƒã‚°ä¿®æ­£
- `docs`: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- `style`: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›´
- `refactor`: ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
- `test`: ãƒ†ã‚¹ãƒˆè¿½åŠ ãƒ»ä¿®æ­£
- `chore`: ãƒ“ãƒ«ãƒ‰ãƒ»è¨­å®šå¤‰æ›´

**Examples:**
```
feat(ai): OpenAI o3ãƒ¢ãƒ‡ãƒ«çµ±åˆã‚’è¿½åŠ 

- ä¸¦åˆ—æ¨è«–å‡¦ç†ã®å®Ÿè£…
- ã‚³ã‚¹ãƒˆè¿½è·¡æ©Ÿèƒ½
- JSONæ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹å¯¾å¿œ

fix(database): PostgreSQLæ¥ç¶šã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£

- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã®èª¿æ•´
- æ¥ç¶šãƒ—ãƒ¼ãƒ«æœ€é©åŒ–
```

### Git Configuration

**User Settings:**
```bash
git config --global user.name "ProjectChimera Dev"
git config --global user.email "dev@projectchimera.local"
git config --global init.defaultBranch main
git config --global pull.rebase false
git config --global core.autocrlf input
```

**Useful Aliases:**
```bash
git config --global alias.st status
git config --global alias.co checkout
git config --global alias.br branch
git config --global alias.ci commit
git config --global alias.lg "log --oneline --graph --decorate --all"
```

## System Design Optimization Guidelines

### Current Architecture Analysis

**Strengths:**
- Complete Docker microservices setup (PostgreSQL + TimescaleDB + Redis)
- Advanced AI integration with o3 model support and parallel inference
- Comprehensive technical analysis using ta-lib
- Full Streamlit web interface implementation

**Critical Issues Identified:**

1. **Database Layer Inconsistency** âœ… RESOLVED
   - Removed legacy `database.py` (SQLite-only implementation)
   - Standardized on `database_adapter.py` (unified SQLite/PostgreSQL support)
   - All modules now use consistent database interface

2. **Data Flow Inconsistencies** âœ… RESOLVED
   - Fixed data structure mismatches in data_collector.py
   - News processing pipeline validated and corrected
   - Added proper field mapping (symbol -> pair, added news ID generation)

3. **Module Implementation Status** âœ… RESOLVED
   - **Audit Complete**: All 16 core modules are fully implemented with high quality
   - **Key Implementations**:
     - Portfolio management with P&L tracking
     - Advanced backtesting with temporal constraints (look-ahead bias prevention)  
     - AI integration with o3 model support and parallel inference
     - Real-time stream processing (Redis-based)
     - Technical analysis with TA-Lib integration
     - Machine learning signal fusion with scikit-learn
     - Performance monitoring and system health checks
   - **Status**: Production-ready architecture

### Implementation Priorities

**Phase 1: Core Stability** âœ… COMPLETED
1. âœ… Database layer unification
2. âœ… Data collector fixes
3. âœ… Core module audit and cleanup
4. â³ Basic test coverage (in progress)

**Phase 2: Integration & Testing (Current Priority)**
5. âœ… All core modules implemented (higher quality than expected)
6. ğŸ”„ End-to-end integration testing (current focus)
7. ğŸ”„ Performance optimization and monitoring setup

**Phase 3: Production Deployment (Next Priority)**
8. ğŸ“‹ Docker environment setup documentation
9. ğŸ“‹ Operational procedures and monitoring
10. ğŸ“‹ User documentation and guides

## ğŸš¨ Critical System Design Issues - DETAILED ANALYSIS

### **PHASE 1: AI Backend Architecture Problems** âœ… AUDITED

**1. Over-Engineered Complexity**
- **Issue**: Redis+Workers+Async processing creates unnecessary fragility
- **Problem**: Single news analysis involves 5+ components with failure points
- **Risk**: Data consistency issues between distributed components

**2. AI Inference Process Flaws**
- **Issue**: No temporal context or market regime awareness
- **Problem**: Individual news analysis without macro environment consideration
- **Risk**: AI decisions ignore market structure and efficiency

**3. Machine Learning Implementation Errors**
```python
# signal_fusion.py:84-89 - CRITICAL BUG
if future_return > 0.01:  # LOOK-AHEAD BIAS
    target = 1  # Using future data for training
```
- **Issue**: Look-ahead bias makes backtests meaningless
- **Problem**: Features lack macroeconomic context
- **Risk**: Overfitted models with no real predictive power

### **PHASE 2: Investment Strategy Fundamental Flaws** âœ… AUDITED

**1. Alpha Generation Theory Gaps**
- **Single News Dependency**: Individual articles cannot generate consistent alpha
- **Market Context Ignorance**: No central bank policy, yield curves, or regime detection
- **Time Horizon Confusion**: News impact timeframes vs trading frequencies misaligned
- **Causality Assumption**: No theoretical basis for newsâ†’return relationships

**2. Risk Management Superficiality**
```python
# risk_manager.py:19-23 - STATIC LIMITS
max_daily_loss_pct = 5.0  # Ignores market volatility regimes
max_position_risk_pct = 1.0  # No Kelly criterion or theoretical basis
```
- **No VaR Implementation**: Missing portfolio-level risk measurement
- **Static Risk Parameters**: No dynamic adjustment for volatility regimes
- **Correlation Blindness**: Currency pair correlations ignored
- **No Regime Detection**: Market state changes not considered

**3. Backtesting Methodology Issues**
```python
# backtester.py:50-80 - LOOK-AHEAD BIAS
# Same-bar stop loss checking creates unrealistic results
```
- **Survivorship Bias**: Failed signals excluded from analysis
- **Transaction Cost Gaps**: Only spread costs, missing slippage/commissions
- **Execution Assumptions**: Perfect liquidity and fill assumptions

### **REQUIRED: Systematic Redesign Framework**

**Investment Strategy Overhaul:**
```
Multi-Factor Alpha Model:
â”œâ”€â”€ Fundamental Layer (40%)
â”‚   â”œâ”€â”€ Central Bank Policy Divergence
â”‚   â”œâ”€â”€ Economic Surprise Indices  
â”‚   â”œâ”€â”€ Yield Curve Dynamics
â”‚   â””â”€â”€ Cross-Asset Flow Analysis
â”œâ”€â”€ Technical Layer (35%)
â”‚   â”œâ”€â”€ Multi-Timeframe Momentum
â”‚   â”œâ”€â”€ Mean Reversion Signals
â”‚   â”œâ”€â”€ Volatility Regime Detection
â”‚   â””â”€â”€ Support/Resistance Dynamics
â”œâ”€â”€ Sentiment Layer (15%)
â”‚   â”œâ”€â”€ Aggregated News Sentiment
â”‚   â”œâ”€â”€ Positioning Data (COT)
â”‚   â”œâ”€â”€ Risk-On/Risk-Off Indicators
â”‚   â””â”€â”€ Currency Strength Indices
â””â”€â”€ Risk Management (10%)
    â”œâ”€â”€ Dynamic Position Sizing (Kelly)
    â”œâ”€â”€ Portfolio-Level VaR
    â”œâ”€â”€ Correlation Matrix Monitoring
    â””â”€â”€ Drawdown Protection Systems
```

**AI Architecture Simplification:**
```
Streamlined Processing:
â”œâ”€â”€ Data Layer
â”‚   â”œâ”€â”€ Economic Data APIs
â”‚   â”œâ”€â”€ Market Data Feeds
â”‚   â””â”€â”€ News Aggregation
â”œâ”€â”€ Feature Engineering
â”‚   â”œâ”€â”€ Macro Factor Calculation
â”‚   â”œâ”€â”€ Technical Indicator Generation
â”‚   â””â”€â”€ Sentiment Scoring
â”œâ”€â”€ Signal Generation
â”‚   â”œâ”€â”€ Factor Ranking Models
â”‚   â”œâ”€â”€ Ensemble Methods
â”‚   â””â”€â”€ Regime-Aware Weighting
â””â”€â”€ Execution Layer
    â”œâ”€â”€ Risk-Adjusted Sizing
    â”œâ”€â”€ Order Management
    â””â”€â”€ Performance Attribution
```

### Development Best Practices

- **Single Source of Truth**: Eliminate duplicate implementations
- **Data Flow Validation**: Ensure type consistency across module boundaries
- **Modular Design**: Keep dependencies minimal and clear
- **Test-Driven**: Validate each component before integration
- **Incremental**: Complete one module fully before moving to next

## Claude Code çŸ¥è¦‹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§çŸ¥è¦‹ã‚’ä½“ç³»çš„ã«ç®¡ç†ã—ã¦ã„ã¾ã™ï¼š

### `.claude/context.md`
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®èƒŒæ™¯ã€ç›®çš„ã€åˆ¶ç´„æ¡ä»¶
- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯é¸å®šç†ç”±  
- ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã‚„æŠ€è¡“çš„åˆ¶ç´„

### `.claude/project-knowledge.md`
- å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„è¨­è¨ˆæ±ºå®šã®çŸ¥è¦‹
- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é¸æŠç†ç”±
- é¿ã‘ã‚‹ã¹ããƒ‘ã‚¿ãƒ¼ãƒ³ã‚„ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³

### `.claude/project-improvements.md`
- éå»ã®è©¦è¡ŒéŒ¯èª¤ã®è¨˜éŒ²
- å¤±æ•—ã—ãŸå®Ÿè£…ã¨ãã®åŸå› 
- æ”¹å–„ãƒ—ãƒ­ã‚»ã‚¹ã¨çµæœ

### `.claude/common-patterns.md`
- é »ç¹ã«ä½¿ç”¨ã™ã‚‹ã‚³ãƒãƒ³ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
- å®šå‹çš„ãªå®Ÿè£…ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

### `.claude/debug-log.md`
- é‡è¦ãªãƒ‡ãƒãƒƒã‚°è¨˜éŒ²
- è§£æ±ºã«æ™‚é–“ã‚’è¦ã—ãŸå•é¡Œ
- ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ‰‹é †

**é‡è¦**: æ–°ã—ã„å®Ÿè£…ã‚„é‡è¦ãªæ±ºå®šã‚’è¡Œã£ãŸéš›ã¯ã€è©²å½“ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚

## Development Commands

### Docker Setup (Recommended)

**Initial Setup:**
```bash
# Install Docker (Amazon Linux 2023)
sudo yum update -y && sudo yum install docker -y
sudo usermod -aG docker ec2-user
sudo systemctl start docker && sudo systemctl enable docker

# Setup project
./scripts/setup.sh
```

**Environment Configuration:**
```bash
# Copy environment template and configure API keys
cp .env.example .env
# Edit .env with your NewsAPI and OpenAI API keys
```

**Docker Operations:**
```bash
# Start all services (PostgreSQL + Redis + App + Collectors)
docker compose up -d

# View logs
docker compose logs -f

# Stop services
docker compose down

# Rebuild after code changes
docker compose build --no-cache && docker compose up -d

# Database backup
./scripts/backup.sh
```

**Service Access:**
- Web UI: http://localhost:8501
- PostgreSQL: localhost:5432
- Redis: localhost:6379


## Architecture Overview

### Core System Components

**Main Application (app.py)**
- Streamlit web interface with 4 main tabs
- Handles API key management (NewsAPI, OpenAI)
- Orchestrates data collection, AI analysis, and backtesting
- Database path: `data/system_data.db`
- Target pair: USD/JPY

**Core Modules (core/)**
- `ai_manager.py`: OpenAI API integration with parallel model inference, cost tracking, and structured JSON response handling
- `portfolio.py`: Trading portfolio simulation with spread consideration, position management, and P&L tracking  
- `backtester.py`: Strategy backtesting engine supporting technical indicators and AI-driven signals

**Data Layer**
- `database.py`: SQLite schema setup with tables for price data, news articles, AI decisions, trade history, and API usage tracking
- `data_collector.py`: YFinance price data and NewsAPI news data collection with database persistence

**Analysis Modules (modules/)**
- `technical_analyzer.py`: SMA crossover signal generation for technical trading strategies

### Data Flow Architecture

1. **Data Collection**: YFinance (price) + NewsAPI (news) â†’ SQLite database
2. **AI Processing**: News articles â†’ OpenAI models â†’ Trade decisions (JSON format)
3. **Signal Generation**: Technical indicators OR AI decisions â†’ Trading signals
4. **Backtesting**: Historical price data + Signals â†’ Portfolio simulation with realistic trading costs
5. **Visualization**: Plotly charts for price action, trade entries/exits, and equity curves

### Key Configuration

- Database: SQLite at `data/system_data.db`
- Default trading pair: USD/JPY
- Price data: 90-day lookback, 1-hour intervals
- News data: 29-day lookback with forex-relevant keywords
- Spread simulation: Configurable pip-based spread costs

### Database Schema Integration

**PostgreSQL + TimescaleDB (Production):**
- `trading.price_data`: Time-series optimized OHLCV data with hypertables
- `trading.news_articles`: News content with AI processing status
- `trading.ai_trade_decisions`: Structured trading recommendations with JSONB storage
- `trading.openai_api_usage`: API cost tracking with time-series optimization
- `trading.trade_history`: Complete trade simulation records
- Automated data retention policies and materialized views for performance

**SQLite (Legacy/Development):**
- Compatible schema for local development and testing
- Simplified table structure without TimescaleDB features

### AI Model Integration

Supports multiple OpenAI models with parallel processing:
- Cost estimation per model/token usage
- Structured JSON response parsing for trade decisions
- Manual analysis logging for model comparison
- Configurable system prompts for different trading strategies

### Docker Architecture

**Services:**
- `postgres`: TimescaleDB container with automated schema initialization
- `redis`: Message streams and caching layer
- `app`: Main Streamlit web interface
- `price_collector`: Scheduled price data collection (1-minute intervals)
- `news_collector`: Scheduled news collection and AI analysis (5-minute intervals)

**Volumes:**
- `postgres_data`: Persistent database storage
- `redis_data`: Redis persistence
- `./data`: Application data directory
- `./logs`: Application logs

**Networks:**
- Isolated `bot_network` for service communication
- Health checks and automatic restarts for reliability

## AI Department System (éƒ¨é–€åˆ¥AIã‚·ã‚¹ãƒ†ãƒ )

### Overview

ProjectChimeraã®æ–°ã—ã„AIéƒ¨é–€ã‚·ã‚¹ãƒ†ãƒ ã¯ã€å°‚é–€åˆ†é‡åˆ¥ã«ç‰¹åŒ–ã—ãŸAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå”èª¿ã—ã¦æŠ•è³‡åˆ¤æ–­ã‚’è¡Œã†å…ˆé€²çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚

### Architecture Components

**Core Components:**
- `AIOrchestrator`: éƒ¨é–€é–“å”èª¿ã‚·ã‚¹ãƒ†ãƒ ã®ä¸­å¤®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼
- `AIAgentBase`: å…¨AIéƒ¨é–€ã®åŸºåº•ã‚¯ãƒ©ã‚¹
- `DepartmentCoordination`: éƒ¨é–€é–“é€£æºç®¡ç†
- `DepartmentPrompts`: éƒ¨é–€åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

**AI Departments:**
1. **Technical Analysis AI** (`TechnicalAnalysisAI`)
   - RSIã€MACDã€ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹ç­‰ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™åˆ†æ
   - ãƒãƒ£ãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ï¼ˆãƒ€ãƒ–ãƒ«ãƒˆãƒƒãƒ—ãƒ»ãƒœãƒˆãƒ ã€ä¸‰è§’ä¿ã¡åˆã„ç­‰ï¼‰
   - ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹åˆ†æ
   - ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ åˆ†æã¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š

2. **Fundamental Analysis AI** (`FundamentalAnalysisAI`)
   - çµŒæ¸ˆæŒ‡æ¨™åˆ†æï¼ˆGDPã€ã‚¤ãƒ³ãƒ•ãƒ¬ã€é›‡ç”¨çµ±è¨ˆç­‰ï¼‰
   - ä¸­å¤®éŠ€è¡Œæ”¿ç­–åˆ†æã¨é‡‘åˆ©å·®è©•ä¾¡
   - åœ°æ”¿å­¦çš„ãƒªã‚¹ã‚¯è©•ä¾¡
   - é€šè²¨ç›¸å¯¾ä¾¡å€¤åˆ†æ

3. **Sentiment Analysis AI** (`SentimentAnalysisAI`)
   - ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®æ„Ÿæƒ…åˆ†æ
   - ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ»ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆè©•ä¾¡
   - å¸‚å ´ææ€–ãƒ»è²ªæ¬²æŒ‡æ•°ã®åˆ†æ
   - ãƒªã‚¹ã‚¯ã‚ªãƒ³ãƒ»ã‚ªãƒ•ã®åˆ¤å®š

4. **Risk Management AI** (`RiskManagementAI`)
   - ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯è©•ä¾¡
   - VaRï¼ˆValue at Riskï¼‰è¨ˆç®—
   - ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³åˆ†æ
   - ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚¸ãƒ³ã‚°æœ€é©åŒ–

5. **Execution & Portfolio AI** (`ExecutionPortfolioAI`)
   - æ³¨æ–‡åŸ·è¡Œæˆ¦ç•¥
   - ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒãƒ©ãƒ³ã‚¹ç®¡ç†
   - æµå‹•æ€§åˆ†æ
   - ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸æœ€å°åŒ–

### Department Coordination System

**Collaboration Rules:**
å„æ±ºå®šã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸéƒ¨é–€é–“å”èª¿ãƒ«ãƒ¼ãƒ«ã‚’å®šç¾©ï¼š

```python
# ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆæ™‚ã®å”èª¿ä¾‹
{
    'required_departments': [TECHNICAL, SENTIMENT, RISK],
    'optional_departments': [FUNDAMENTAL],
    'consensus_threshold': 0.6,
    'weights': {
        'TECHNICAL': 0.35,
        'FUNDAMENTAL': 0.25, 
        'SENTIMENT': 0.20,
        'RISK': 0.20
    }
}
```

**Decision Types:**
- `TRADE_SIGNAL`: ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ
- `RISK_ASSESSMENT`: ãƒªã‚¹ã‚¯è©•ä¾¡
- `MARKET_ANALYSIS`: å¸‚å ´åˆ†æ
- `PORTFOLIO_REBALANCE`: ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªãƒãƒ©ãƒ³ã‚¹
- `EMERGENCY_ACTION`: ç·Šæ€¥æ™‚å¯¾å¿œ

### Integration Features

**Parallel Processing:**
- è¤‡æ•°éƒ¨é–€ã«ã‚ˆã‚‹ä¸¦è¡Œåˆ†æå‡¦ç†
- éåŒæœŸå‡¦ç†ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½

**Consensus Building:**
- é‡ã¿ä»˜ãã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹è¨ˆç®—
- ä¿¡é ¼åº¦é–¾å€¤ã«ã‚ˆã‚‹æ„æ€æ±ºå®šãƒ•ã‚£ãƒ«ã‚¿
- éƒ¨é–€é–“æ„è¦‹ã®çµ±åˆãƒ­ã‚¸ãƒƒã‚¯

**Performance Monitoring:**
- éƒ¨é–€åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
- ã‚³ã‚¹ãƒˆç®¡ç†ï¼ˆAPIä½¿ç”¨æ–™ç­‰ï¼‰
- å‡¦ç†æ™‚é–“ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### Usage Example

```python
from core.ai_orchestrator import AIOrchestrator, MarketSituation
from departments.technical_analysis_ai import TechnicalAnalysisAI

# ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–
orchestrator = AIOrchestrator()

# éƒ¨é–€ç™»éŒ²
orchestrator.register_department(DepartmentType.TECHNICAL, TechnicalAnalysisAI())

# å¸‚å ´åˆ†æå®Ÿè¡Œ
market_data = MarketSituation(
    price_data={'close': 150.5, 'volume': 100000},
    technical_indicators={'rsi': 65.0},
    news_data=[...],
    timestamp=datetime.now()
)

decision = await orchestrator.analyze_market_situation(
    market_data, 
    DecisionType.TRADE_SIGNAL
)

print(f"Action: {decision.final_decision['action']}")
print(f"Confidence: {decision.consensus_confidence:.3f}")
```

### Testing

**Integration Tests:**
- `test_ai_department_simple.py`: ãƒ¢ãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ã®çµ±åˆãƒ†ã‚¹ãƒˆ
- éƒ¨é–€ç™»éŒ²ã€å¸‚å ´åˆ†æã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ¤œè¨¼
- 100%ãƒ†ã‚¹ãƒˆæˆåŠŸç‡ã‚’é”æˆ

**Test Coverage:**
- éƒ¨é–€ç™»éŒ²æ©Ÿèƒ½
- å¸‚å ´çŠ¶æ³åˆ†æ
- è¤‡æ•°ã‚·ãƒŠãƒªã‚ªå¯¾å¿œ
- ã‚¨ãƒ©ãƒ¼å‡¦ç†
- çµ±è¨ˆæƒ…å ±ç®¡ç†

### Benefits

1. **å°‚é–€æ€§**: å„éƒ¨é–€ãŒç‰¹å®šåˆ†é‡ã«ç‰¹åŒ–ã—ãŸé«˜åº¦ãªåˆ†æ
2. **å”èª¿æ€§**: è¤‡æ•°ã®è¦–ç‚¹ã‚’çµ±åˆã—ãŸç·åˆçš„åˆ¤æ–­
3. **æ‹¡å¼µæ€§**: æ–°ã—ã„éƒ¨é–€ã®è¿½åŠ ãŒå®¹æ˜“
4. **ä¿¡é ¼æ€§**: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
5. **é€æ˜æ€§**: å„éƒ¨é–€ã®åˆ¤æ–­æ ¹æ‹ ãŒæ˜ç¢º

ã“ã®AIéƒ¨é–€ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šã€ProjectChimeraã¯å¾“æ¥ã®å˜ä¸€AIãƒ¢ãƒ‡ãƒ«ã‚’è¶…ãˆãŸã€ã‚ˆã‚Šæ´—ç·´ã•ã‚ŒãŸæŠ•è³‡åˆ¤æ–­ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚

# Projectâ€¯Chimera â€“ Claudeâ€‘Code Development Reference

> *This markdown is a living spec & cribâ€‘sheet for anyone (or any agent) contributing code to the Bitgetâ€‘only alphaâ€‘stack.*

---

## 0. Purpose

Provide **one authoritative page** that Claudeâ€‘Code (or other LLMâ€‘agents) can ingest in a single prompt to know:

* What weâ€™re building and why
* Which modules already exist vs. still missing
* Coding, testing, and deployment conventions

---

## 1. Topâ€‘Level Goal

**Turn a 150â€¯kâ€¯JPY account into a compounding, riskâ€‘capped trading bot** by stacking seven shortâ€‘term alpha strategies on Bitget and automating everything from datafeed to monitoring.

---

## 2. Canonical References

| Doc / Repo                              | Why it matters                       |
| --------------------------------------- | ------------------------------------ |
| `github.com/burmf/ProjectChimera`       | Main codebase (current prototype)    |
| This `claude.md`                        | Master spec for Claudeâ€‘Code          |
| Phase plan Bâ†’G block (2025â€‘06â€‘18)       | Roadâ€‘map tasks & acceptance criteria |
| Strategy Catalog table (seven â­ strats) | Exact trading logic to implement     |
| Riskâ€‘Engine spec (Dynâ€‘Kelly/ATR/DD)     | Capital protection rules             |

---

## 3. Architecture Snapshot

```mermaid
graph TD
  WS[Bitget WebSocket] --> Hub(StrategyHub)
  Rest[Bitget REST] --> Hub
  Hub --> Risk(RiskEngine)
  Risk --> Exec(Execution REST)
  Exec --> Logger
  Logger -->|pnl_total| Prom
  UI(Streamlit) -->|control| Hub
```

---

## 4. PhaseÂ DÂ â†’Â G Checklist (abbr.)

1. **D â€“ Risk & Leverage**
   `risk/dyn_kelly.py`, `atr_target.py`, `dd_guard.py`
2. **E â€“ Optimiser / Backtest CLI**
   `cli/backtest.py`, `cli/optimise.py` (Optuna 50 trials)
3. **F â€“ Live Orchestrator**
   `orchestrator.py`, circuitâ€‘breaker, health endpoint
4. **G â€“ Monitoring & Dashboard**
   Prometheus exporter, Grafana JSON, Streamlit control

---

## 5. Strategy Modules (MVP 7)

| File                | Alias        | Core trigger                       |
| ------------------- | ------------ | ---------------------------------- |
| `weekend_effect.py` | WKND\_EFF    | FriÂ 23:00Â UTC buy â†’ MonÂ 01:00 sell |
| `stop_rev.py`       | STOP\_REV    | Â 5â€¯mÂ âˆ’3â€¯% & volÂ Ã—3Â â†’ long rebound  |
| `fund_contra.py`    | FUND\_CONTRA | Â Funding Â±0.03â€¯% & OI spike        |
| `lob_revert.py`     | LOB\_REV     | Â Orderâ€‘flow RSIÂ >70/<30            |
| `vol_breakout.py`   | VOL\_BRK     | Â BB squeeze & Â±2â€¯% breakout        |
| `cme_gap.py`        | CME\_GAP     | Â Weekend futures gap fill          |
| `basis_arb.py`      | BASIS\_ARB   | Â SpotÂ â†”Â Perp premiumÂ >Â 0.5â€¯%       |

*Each exposes* `generate(frame)->Signal`  *and* `on_fill()`

---

## 6. Riskâ€‘Engine Rules

```text
size_nominal = equity * kelly_frac * target_vol/ATR
if DD â‰¥10% â‡’ sizeÃ—0.5
if DD â‰¥20% â‡’ flat & pause 24h
```

Default: `kelly_frac=0.5`, `target_vol=1%/day`.

---

## 7. Data Sources

* WS Channels: `books`, `trade`, `ticker`, `fundingRate`, `account` (OI)
* REST Endpoints: candlesÂ 1m, fundingâ€‘history, openâ€‘interest

---

## 8. Coding Guidelines

* **AsyncIO everywhere** (`httpx.AsyncClient`, `websockets`).
* Use *dependencyâ€‘injector* for all singletons (feed, http).
* Follow `ruff`, `black`, `isort`. CI fails on style error.

---

## 9. Testing & CI

* PyTest + `pytestâ€‘httpx` mocks.
* Target coverage â‰¥â€¯60â€¯%; enforced in GH Actions.

---

## 10. Docker / Ops

* Multiâ€‘stage Dockerfile â†’ final image <â€¯100â€¯MB.
* `HEALTHCHECK curl localhost:8000/health`.
* `docker-compose up` spins: bot, redis, postgres, prom, grafana.

---

## 11. Open TODOs

* [ ] Finish `bitget_ws.py` latency-safe implementation.
* [ ] Implement **WKND\_EFF, STOP\_REV, FUND\_CONTRA** first.
* [ ] Integrate Dyn-Kelly & DD guard in live loop.
* [ ] Add prom metric `ws_latency_ms`.
* [ ] Write e2e smoke test (`tests/e2e_demo.py`).

---

## 12. Design Philosophy â€” *For a Firstâ€‘Year Engineer*

> *Guiding principles so even a brandâ€‘new coder can navigate the codebase with confidence.*

1. **Singleâ€‘Responsibility Modules**
   Each file should *do one thing well*: feed, strategy, risk, or execution. Fewer imports = easier mental model.
2. **Failâ€‘Fast, Safeâ€‘Fail**
   Catch exceptions at the boundary (API calls) and let async tasks crashâ€‘restart; never swallow errors silently.
3. **Asyncâ€‘First Thinking**
   â€‘ Prefer `await httpx` / `async for ws` over blocking loops.
   â€‘ CPUâ€‘light â†’ I/Oâ€‘bound, so latency is king.
4. **Config over Code**
   Numbers (thresholds, keys) live in `settings.yaml`. Changing behaviour should never need a code edit.
5. **Test Small, Test Often**
   For every new function, add a pytest. Aim: *red â†’ green â†’ refactor*. Coverage is a safety net.
6. **Log Everything Important**
   JSON logs with `ts, level, event, pair, pnl` so Grafana can graph any metric later.
7. **Risk First, Profit Second**
   If DD guard fires, strategy *must* shrink/stop. Protect equity; compounding only works when survival > 0.
8. **Readability > Cleverness**
   Choose clarity over microâ€‘optimisation. Futureâ€‘you (and AI reviewers) will thank you.

> **TL;DR**: *Small pieces, clear contracts, observable behaviour, and safety railsâ€”then add alpha.*

---
